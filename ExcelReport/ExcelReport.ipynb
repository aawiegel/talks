{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to make Excel workbooks the easy way with Python and xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aaron Wiegel, PhD, Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyBay 2018 Lightning Talk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthego, a CRISPR/Cas9 manufacturing biotech startup\n",
    "![crispr-cas9-sgrna](https://help.synthego.com/hc/article_attachments/360000535107/image__1_.png)\n",
    "\n",
    "_Courtsey of Synthego_\n",
    "\n",
    "- Chemistry (RNA synthesis) and Biology (Gene edited cell pools)\n",
    "- Hardware and Systems Engineering (Robots!)\n",
    "- Software Engineering (Mostly **_Python_**, some of that...... `JavaScript` thing)\n",
    "- Data Science and Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem\n",
    "\n",
    "Head of operations wants high-level KPI metrics to report to exeuctives.\n",
    "\n",
    "I have the data to generate these, but in a 1500 column 300 MB CSV file generated from our internal Django REST API for manufacturing.\n",
    "\n",
    "We haven't hired a Data Engineer to build proper infrastructure yet.\n",
    "\n",
    "I don't want to waste my valuable time dealing with clicking around the horrible Excel GUI to make graphs. (I had enough of that from when I was a grad student. <--- why do you think I learned Python?)\n",
    "\n",
    "![tps_reports](https://media.giphy.com/media/3owyoUHuSSqDMEzVRu/giphy.gif)\n",
    "\n",
    "(c) Fox 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The solution: xlsxwriter!\n",
    "\n",
    "Well-documented open-source Python package that allows for automatic generation of Excel workbooks with graphs and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_order_id</th>\n",
       "      <th>sales_order_datetime</th>\n",
       "      <th>manufacturing_start_datetime</th>\n",
       "      <th>manufacturing_completed_datetime</th>\n",
       "      <th>shipped_datetime</th>\n",
       "      <th>attempts</th>\n",
       "      <th>pass_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-07 00:03:00</td>\n",
       "      <td>2018-01-07 04:09:22</td>\n",
       "      <td>2018-01-09 11:38:29</td>\n",
       "      <td>2018-01-10 04:13:02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-07 00:07:57</td>\n",
       "      <td>2018-01-07 03:58:25</td>\n",
       "      <td>2018-01-08 10:39:03</td>\n",
       "      <td>2018-01-09 03:44:39</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-07 00:13:41</td>\n",
       "      <td>2018-01-07 06:44:16</td>\n",
       "      <td>2018-01-11 22:30:43</td>\n",
       "      <td>2018-01-12 12:06:08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-07 00:34:54</td>\n",
       "      <td>2018-01-07 05:50:40</td>\n",
       "      <td>2018-01-08 17:26:05</td>\n",
       "      <td>2018-01-09 06:31:29</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-07 00:58:50</td>\n",
       "      <td>2018-01-07 06:33:56</td>\n",
       "      <td>2018-01-12 05:32:17</td>\n",
       "      <td>2018-01-12 21:24:42</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales_order_id sales_order_datetime manufacturing_start_datetime  \\\n",
       "0               1  2018-01-07 00:03:00          2018-01-07 04:09:22   \n",
       "1               2  2018-01-07 00:07:57          2018-01-07 03:58:25   \n",
       "2               3  2018-01-07 00:13:41          2018-01-07 06:44:16   \n",
       "3               4  2018-01-07 00:34:54          2018-01-07 05:50:40   \n",
       "4               5  2018-01-07 00:58:50          2018-01-07 06:33:56   \n",
       "\n",
       "  manufacturing_completed_datetime     shipped_datetime  attempts  pass_rate  \n",
       "0              2018-01-09 11:38:29  2018-01-10 04:13:02         2   0.500000  \n",
       "1              2018-01-08 10:39:03  2018-01-09 03:44:39         1   1.000000  \n",
       "2              2018-01-11 22:30:43  2018-01-12 12:06:08         3   0.333333  \n",
       "3              2018-01-08 17:26:05  2018-01-09 06:31:29         1   1.000000  \n",
       "4              2018-01-12 05:32:17  2018-01-12 21:24:42         5   0.200000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "DEFAULT_PATH = os.path.join(os.path.expanduser('~'), 'side/talks/ExcelReport')\n",
    "DEFAULT_CSV_FILE = 'manufacturing_data.csv'\n",
    "DEFAULT_OUTPUT_FILE = 'tps_report.xlsx'\n",
    "DAYS_AGO = 365\n",
    "\n",
    "df = pd.read_csv(os.path.join(DEFAULT_PATH, 'manufacturing_data.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPSReport:\n",
    "    # Constants, see below\n",
    "    INTEGER_COLUMNS = ('sales_orders', 'overproduction')\n",
    "    PERCENT_COLUMNS = ('pass_rate', 'percent_on_time_shipments')\n",
    "    \n",
    "    def __init__(self, data_path=DEFAULT_PATH, input_file=DEFAULT_CSV_FILE, \n",
    "                 output_file='tps_report.xlsx', days_ago=DAYS_AGO, date_column='shipped_datetime'):\n",
    "        \n",
    "        # Set up file paths\n",
    "        self.input_path = os.path.join(data_path, input_file)\n",
    "        self.output_xlsx_path = os.path.join(data_path, output_file)\n",
    "        \n",
    "        # Set up filter criteria\n",
    "        self.days_ago = days_ago\n",
    "        \n",
    "        # Load data\n",
    "        self.input_df = self._load_input_data(date_column)\n",
    "        \n",
    "    def _load_input_data(self, date_column):\n",
    "        \"\"\"load input csv and do some basic clean up\"\"\"\n",
    "        df = pd.read_csv(self.input_path)\n",
    "        \n",
    "        df = self._process_input_df(df, date_column)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def _process_input_df(self, df, date_column):\n",
    "        \"\"\"Do some basic filtering of initial data\"\"\"\n",
    "        start_date = datetime.utcnow() - timedelta(days=self.days_ago)\n",
    "        \n",
    "        # Convert to datetime, filter dataframe\n",
    "        df['sales_order_datetime'] = pd.to_datetime(df['sales_order_datetime'])\n",
    "        df['manufacturing_start_datetime'] = pd.to_datetime(df['manufacturing_start_datetime'])\n",
    "        df['manufacturing_completed_datetime'] = pd.to_datetime(df['manufacturing_completed_datetime'])\n",
    "        df['shipped_datetime'] = pd.to_datetime(df['shipped_datetime'])\n",
    "        \n",
    "        df = df[df[date_column] >= start_date]\n",
    "        df.set_index(date_column, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def calculate_metrics(self):\n",
    "        \"\"\"process data to create higher level metrics\"\"\"\n",
    "        \n",
    "        # Calculate timing metrics on individual orders\n",
    "        self.input_df['manufacturing_lead_time'] = (self.input_df['manufacturing_start_datetime']\n",
    "                                              - self.input_df['sales_order_datetime']) / np.timedelta64(1, 'h')\n",
    "        \n",
    "        self.input_df['manufacturing_time'] = (self.input_df['manufacturing_completed_datetime'] \n",
    "                                         - self.input_df['manufacturing_start_datetime']) / np.timedelta64(1, 'h')\n",
    "        \n",
    "        self.input_df['shipping_lead_time'] = (self.input_df.index\n",
    "                                         - self.input_df['manufacturing_completed_datetime']) / np.timedelta64(1, 'h')\n",
    "        \n",
    "        self.input_df['turn_around_time'] = (self.input_df.index\n",
    "                                       - self.input_df['sales_order_datetime']) / np.timedelta64(1, 'D')\n",
    "        \n",
    "        self.input_df['on_time_shipment'] = self.input_df['turn_around_time'] <= 6\n",
    "        \n",
    "        # Calculate weekly KPIs by resampling on datetime index\n",
    "        resampler = self.input_df.resample('1w', label='left')\n",
    "        \n",
    "        # Count number of sales orders and overproduction\n",
    "        df = pd.DataFrame(resampler['sales_order_id'].count())\n",
    "        df.rename(columns={'sales_order_id': 'sales_orders'}, inplace=True)\n",
    "        \n",
    "        df['overproduction'] = resampler['attempts'].sum()\n",
    "        df['pass_rate'] = df['sales_orders'] / df['overproduction']\n",
    "        \n",
    "        # Calculate descriptive metrics for process timings\n",
    "        timing_columns = [column for column in self.input_df.columns if column.endswith('_time')]\n",
    "        for column in timing_columns:\n",
    "            df[column+'_mean'] = resampler[column].mean()\n",
    "            df[column+'_median'] = resampler[column].median()\n",
    "            df[column+'_90th_percentile'] = resampler[column].quantile(q=0.9)\n",
    "            \n",
    "        df['percent_on_time_shipments'] = resampler['on_time_shipment'].mean()\n",
    "        \n",
    "        # Rename index, drop time part\n",
    "        df.index = df.index.strftime('%Y-%m-%d')\n",
    "        df.index.rename('Week', inplace=True)\n",
    "        \n",
    "        self.output_df = df\n",
    "    \n",
    "    def format_and_write_report(self, graph_dicts):\n",
    "        \"\"\"write data and graphs to separate work sheets\"\"\"\n",
    "        writer = pd.ExcelWriter(self.output_xlsx_path, engine='xlsxwriter')\n",
    "        \n",
    "        self._write_summary_stats(writer)\n",
    "        \n",
    "        self._write_summary_graphs(writer, graph_dicts)\n",
    "        \n",
    "        writer.save()\n",
    "        \n",
    "        # Add stuff here to say, upload to s3, tableau sever, whatever\n",
    "        \n",
    "    def _write_summary_stats(self, writer, sheet_name='overall KPIs'):\n",
    "        \"\"\"write and format Excel worksheet with KPIs\"\"\" \n",
    "        \n",
    "        self.output_df.to_excel(writer, sheet_name=sheet_name)\n",
    "        \n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "        \n",
    "        # Freeze top row\n",
    "        # worksheet.freeze_panes(row, col[, top_row, left_col])\n",
    "        worksheet.freeze_panes(1, 0)\n",
    "        \n",
    "        # Add number formats\n",
    "        percentage = workbook.add_format({'num_format': '0%', 'align': 'right'})\n",
    "        truncated_decimal = workbook.add_format({'num_format': '0.00', 'align': 'right'})\n",
    "        integer = workbook.add_format({'num_format': '#,###', 'align': 'center'})\n",
    "        date = workbook.add_format({'num_format': 'yyyy-mm-dd', 'align': 'left'})\n",
    "        \n",
    "        # Format first column from index to use date format\n",
    "        # worksheet.set_column(first_col, last_col, width, cell_format, options)\n",
    "        worksheet.set_column(0, 0, len(self.output_df.values[0]), date)\n",
    "        \n",
    "        # Get last row number\n",
    "        last_row = len(self.output_df)\n",
    "        \n",
    "        # Format other columns (remember index isn't included in pandas dataframe, but is with Excel)\n",
    "        for column_index, column in enumerate(self.output_df.columns, start=1):\n",
    "            if column in self.INTEGER_COLUMNS:\n",
    "                worksheet.set_column(column_index, column_index, len(column), integer)\n",
    "                \n",
    "            elif column in self.PERCENT_COLUMNS:\n",
    "                # Conditional formatting needs to be set outside other formatting\n",
    "                # worksheet.conditional_format(first_row, first_col, last_row, last_col, options)\n",
    "                worksheet.conditional_format(1, column_index, last_row, column_index,\n",
    "                                             {\n",
    "                                              'type': '2_color_scale',\n",
    "                                              'min_type': 'num', 'max_type': 'num',\n",
    "                                              'min_value': 0.0, 'max_value': 1.0,\n",
    "                                              'min_color': '#f27285',\n",
    "                                              'max_color': '#ffffff'\n",
    "                                             })\n",
    "                \n",
    "                worksheet.set_column(column_index, column_index, len(column), percentage)\n",
    "            else:\n",
    "                worksheet.set_column(column_index, column_index, len(column), truncated_decimal)\n",
    "        \n",
    "    def _write_summary_graphs(self, writer, graph_dicts, sheet_name='KPI graphs'):\n",
    "        \"\"\"create graphs from graph dict\"\"\"\n",
    "        \n",
    "        \n",
    "        workbook = writer.book\n",
    "        worksheet = workbook.add_worksheet(sheet_name)\n",
    "        \n",
    "        # Create marker to track place of graph\n",
    "        i = 1\n",
    "        for graph_dict in graph_dicts:\n",
    "            # Create new chart object\n",
    "            chart = self._create_chart(workbook, graph_dict)\n",
    "            worksheet.insert_chart('A'+str(i), chart)\n",
    "            i += 15\n",
    "            \n",
    "    def _create_chart(self, workbook, graph_dict):\n",
    "        \"\"\"create new chart and plot values (y) versus categories (x) with axis label\"\"\"\n",
    "        min_row = 1\n",
    "        max_row = len(self.output_df)\n",
    "        data_sheet_name = graph_dict['data_sheet_name']\n",
    "        \n",
    "        chart_dict = {'type': graph_dict['chart_type']}\n",
    "        subtype = graph_dict.get('subtype')\n",
    "        if subtype is not None:\n",
    "            chart_dict['subtype'] = subtype\n",
    "        \n",
    "        chart = workbook.add_chart(chart_dict)\n",
    "        \n",
    "        # Plot each value in series\n",
    "        for value in graph_dict['values']:\n",
    "            # Remember index is written to Excel workbook as column 0 but not included in the pandas columns\n",
    "            value_index = self.output_df.columns.get_loc(value) + 1\n",
    "            \n",
    "            chart.add_series({\n",
    "                # Get name from first row of data sheet\n",
    "                'name': [data_sheet_name, 0, value_index],\n",
    "                'categories': [data_sheet_name, min_row, 0, max_row, 0],\n",
    "                'values': [data_sheet_name, min_row, value_index, max_row, value_index]\n",
    "            })\n",
    "        \n",
    "        chart.set_y_axis({'name': graph_dict['axis_label'], 'major_gridlines': {'visible': False}})\n",
    "        chart.set_x_axis({'name': graph_dict['category'], 'date_axis': True})\n",
    "        \n",
    "        return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TPSReport()\n",
    "report.calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dicts = [\n",
    "    {\n",
    "        'data_sheet_name': 'overall KPIs',\n",
    "        'chart_type': 'line',\n",
    "        'category': 'Week',\n",
    "        'values': ('overproduction',),\n",
    "        'axis_label': 'Overproduction',\n",
    "    },\n",
    "    {\n",
    "        'data_sheet_name': 'overall KPIs',\n",
    "        'chart_type': 'line',\n",
    "        'category': 'Week',\n",
    "        'values': ('turn_around_time_mean',\n",
    "                   'turn_around_time_median',\n",
    "                   'turn_around_time_90th_percentile'),\n",
    "        'axis_label': 'Manufacturing Lead Time',\n",
    "    },\n",
    "    {\n",
    "        'data_sheet_name': 'overall KPIs',\n",
    "        'chart_type': 'column',\n",
    "        'subtype': 'stacked',\n",
    "        'category': 'Week',\n",
    "        'values': ('manufacturing_lead_time_mean',\n",
    "                   'manufacturing_time_mean',\n",
    "                   'shipping_lead_time_mean'),\n",
    "        'axis_label': 'Process Timing'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.format_and_write_report(graph_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big impact from a small report\n",
    "\n",
    "- Weekly cronjob provided much better visibility into production trends (along with several other regular more detailed reports)\n",
    "- Useful stopgap solution as we have been developing more robust and functional alternatives (data warehouse, Tableau)\n",
    "- Simple, small things can make a big difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!\n",
    "![Synthego](https://orders.synthego.com/static/images/synthego-logo.svg)\n",
    "\n",
    "[XlsxWriter](https://xlsxwriter.readthedocs.io/) <--- great documentation!\n",
    "\n",
    "[https://github.com/aawiegel/talks/tree/master/ExcelReport](https://github.com/aawiegel/talks/tree/master/ExcelReport)\n",
    "\n",
    "*If you know of a package that does the same thing with Tableau workbooks, please come talk to me immediately!*\n",
    "\n",
    "We're hiring! \n",
    "\n",
    "- Full Stack Software Engineers for various roles (LIMS, Commercial, Computational Biology) using Django (No Biology knowledge required)\n",
    "- Bioinformatics \n",
    "\n",
    "(I promise you will not be asked to automatically generate Excel workbooks.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
